{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMArpOQFukYE16CT1pXLZMZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BoilerToad/COVID-19/blob/master/Pytorch_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ2e37Uq2hU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eac90d85-2e1d-4baa-8e69-ca648d0b13d0"
      },
      "source": [
        "!git clone https://github.com/dongjun-Lee/text-summarization-tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'text-summarization-tensorflow'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Total 48 (delta 0), reused 0 (delta 0), pack-reused 48\u001b[K\n",
            "Unpacking objects: 100% (48/48), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "J30gY6cfDHmL",
        "outputId": "00cc7e66-0567-4643-c4d3-61109d05d3bc"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a8055ced-d10b-41f3-9c86-03822d98897b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a8055ced-d10b-41f3-9c86-03822d98897b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving summary.tar.gz to summary.tar.gz\n",
            "User uploaded file \"summary.tar.gz\" with length 290866023 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blIwByFeEkbU",
        "outputId": "4be79433-35fd-4354-c8b2-5ee56ca21146"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive\n",
        "#drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTse99OTF4NZ",
        "outputId": "c2e72a16-80a7-42b6-f2c8-3664ea786656"
      },
      "source": [
        "%ls -l"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8\n",
            "drwx------ 5 root root 4096 Feb  6 23:35 \u001b[0m\u001b[01;34mdrive\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 Feb  4 15:26 \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7qP9qUPGzb-",
        "outputId": "69de3fb2-f237-48c5-8b9e-75b5fec85ca6"
      },
      "source": [
        "%cd /content/drive/MyDrive/ColabNotebooks\n",
        "%ls -l"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ColabNotebooks\n",
            "total 49\n",
            "drwx------ 4 root root  4096 Feb  6 18:19 \u001b[0m\u001b[01;34mNLP\u001b[0m/\n",
            "-rw------- 1 root root 45728 Feb  6 23:45 Pytorch_example.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOe1TlHiG2K6",
        "outputId": "4dc0f98d-b17e-49a4-d7b9-184098a6f041"
      },
      "source": [
        "%cd '/content/drive/MyDrive/ColabNotebooks/NLP/text_summarization'\n",
        "%ls -l"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/ColabNotebooks/NLP/text_summarization'\n",
            "/content/drive/MyDrive/ColabNotebooks\n",
            "total 49\n",
            "drwx------ 4 root root  4096 Feb  6 18:19 \u001b[0m\u001b[01;34mNLP\u001b[0m/\n",
            "-rw------- 1 root root 45728 Feb  6 23:45 Pytorch_example.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7s9xxbmJapv",
        "outputId": "084e5046-045f-499e-ad3d-de3418968abd"
      },
      "source": [
        "# Clone github repository setup\n",
        "# import join used to join ROOT path and MY_GOOGLE_DRIVE_PATH\n",
        "from os.path import join  \n",
        "\n",
        "# path to your project on Google Drive\n",
        "MY_GOOGLE_DRIVE_PATH = '/content/drive/My Drive/ColabNotebooks/NLP' \n",
        "# replace with your Github username \n",
        "GIT_USERNAME = \"BoilerToad\" \n",
        "# definitely replace with your\n",
        "GIT_TOKEN = \"1664e3d5c3bbf4630a6ca516b2473785c2d6842a\"  \n",
        "# Replace with your github repository in this case we want \n",
        "# to clone deep-learning-v2-pytorch repository\n",
        "GIT_REPOSITORY = \"text-summarization-tensorflow\" \n",
        "\n",
        "PROJECT_PATH = join(ROOT, MY_GOOGLE_DRIVE_PATH)\n",
        "\n",
        "# It's good to print out the value if you are not sure \n",
        "print(\"PROJECT_PATH: \", PROJECT_PATH)   \n",
        "\n",
        "# In case we haven't created the folder already; we will create a folder in the project path \n",
        "!mkdir \"{PROJECT_PATH}\"    \n",
        "\n",
        "#GIT_PATH = \"https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/{GIT_REPOSITORY}.git\" this return 400 Bad Request for me\n",
        "GIT_PATH = \"https://\" + GIT_TOKEN + \"@github.com/\" + GIT_USERNAME + \"/\" + GIT_REPOSITORY + \".git\"\n",
        "print(\"GIT_PATH: \", GIT_PATH)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PROJECT_PATH:  /content/drive/My Drive/ColabNotebooks/NLP\n",
            "mkdir: cannot create directory ‘/content/drive/My Drive/ColabNotebooks/NLP’: File exists\n",
            "GIT_PATH:  https://1664e3d5c3bbf4630a6ca516b2473785c2d6842a@github.com/BoilerToad/text-summarization-tensorflow.git\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv8G3r8JkCk6",
        "outputId": "31651447-d902-415b-ee9a-6c81ccc913da"
      },
      "source": [
        "%cd '/content/drive/My Drive/ColabNotebooks/NLP'"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ColabNotebooks/NLP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z6e8bXVdie8",
        "outputId": "8f0e6372-4728-4b1b-e907-b4fba97f55b5"
      },
      "source": [
        "#%cd \"{PROJECT_PATH}\"    # Change directory to the location defined in project_path\n",
        "!git clone \"{GIT_PATH}\" # clone the github repository"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'text-summarization-tensorflow' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEtXF8nMmq0m",
        "outputId": "8161dc88-f90a-4df2-d929-6a8c870b3931"
      },
      "source": [
        "# Clone github repository setup\n",
        "# import join used to join ROOT path and MY_GOOGLE_DRIVE_PATH\n",
        "from os.path import join  \n",
        "\n",
        "# path to your project on Google Drive\n",
        "MY_GOOGLE_DRIVE_PATH = '/content/drive/My Drive/ColabNotebooks/NLP' \n",
        "# replace with your Github username \n",
        "GIT_USERNAME = \"BoilerToad\" \n",
        "# definitely replace with your\n",
        "GIT_TOKEN = \"1664e3d5c3bbf4630a6ca516b2473785c2d6842a\"  \n",
        "# Replace with your github repository in this case we want \n",
        "# to clone deep-learning-v2-pytorch repository\n",
        "GIT_REPOSITORY = \"sent-summary\" \n",
        "\n",
        "PROJECT_PATH = join(ROOT, MY_GOOGLE_DRIVE_PATH)\n",
        "\n",
        "# It's good to print out the value if you are not sure \n",
        "print(\"PROJECT_PATH: \", PROJECT_PATH)   \n",
        "\n",
        "# In case we haven't created the folder already; we will create a folder in the project path \n",
        "!mkdir \"{PROJECT_PATH}\"    \n",
        "\n",
        "#GIT_PATH = \"https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/{GIT_REPOSITORY}.git\" this return 400 Bad Request for me\n",
        "GIT_PATH = \"https://\" + GIT_TOKEN + \"@github.com/\" + GIT_USERNAME + \"/\" + GIT_REPOSITORY + \".git\"\n",
        "print(\"GIT_PATH: \", GIT_PATH)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PROJECT_PATH:  /content/drive/My Drive/ColabNotebooks/NLP\n",
            "mkdir: cannot create directory ‘/content/drive/My Drive/ColabNotebooks/NLP’: File exists\n",
            "GIT_PATH:  https://1664e3d5c3bbf4630a6ca516b2473785c2d6842a@github.com/BoilerToad/sent-summary.git\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srvnGwgMmBEN",
        "outputId": "df950d75-f1e0-46d1-dbc2-901ae5610228"
      },
      "source": [
        "!git clone \"{GIT_PATH}\" # clone the github repository"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'sent-summary'...\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Total 13 (delta 0), reused 0 (delta 0), pack-reused 13\u001b[K\n",
            "Unpacking objects: 100% (13/13), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sivuNx07fL-b",
        "outputId": "3b5848a7-f488-4ad4-a7a7-46f22bcc2a1c"
      },
      "source": [
        "%cd text-summarization-tensorflow\n",
        "%ls -l"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ColabNotebooks/NLP/text-summarization-tensorflow\n",
            "total 284835\n",
            "drwx------ 2 root root      4096 Feb  6 18:59 \u001b[0m\u001b[01;34mglove\u001b[0m/\n",
            "-rw------- 1 root root      1068 Feb  6 18:18 LICENSE\n",
            "-rw------- 1 root root      6939 Feb  6 18:18 model.py\n",
            "-rw------- 1 root root       999 Feb  6 18:18 prep_data.py\n",
            "drwx------ 2 root root      4096 Feb  6 19:17 \u001b[01;34m__pycache__\u001b[0m/\n",
            "-rw------- 1 root root      5109 Feb  6 18:18 README.md\n",
            "-rw------- 1 root root        36 Feb  6 18:18 requirements.txt\n",
            "-rw------- 1 root root    765674 Feb  6 18:18 sample_data.zip\n",
            "drwx------ 2 root root      4096 Apr 12  2016 \u001b[01;34msumdata\u001b[0m/\n",
            "-rw------- 1 root root 290866023 Feb  6 18:35 summary.tar.gz\n",
            "-rw------- 1 root root      1771 Feb  6 18:18 test.py\n",
            "-rw------- 1 root root      4388 Feb  6 18:18 train.py\n",
            "-rw------- 1 root root      4023 Feb  6 18:18 utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voF_wEFahZQe",
        "outputId": "339f6e78-516c-45cd-9fcf-c133b046222f"
      },
      "source": [
        "!git status"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On branch master\n",
            "Your branch is up to date with 'origin/master'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LASoJx6Mleji",
        "outputId": "acd10fcd-2c5b-4e35-911d-de47a6d44de3"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim==3.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/50/b3ea3db5ce57b215d88e58d64e32924596e78f35bdfa229735a1ee1e86cb/gensim-3.3.0-cp36-cp36m-manylinux1_x86_64.whl (22.5MB)\n",
            "\u001b[K     |████████████████████████████████| 22.5MB 1.4MB/s \n",
            "\u001b[?25hCollecting wget==3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Requirement already satisfied: nltk==3.2.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (3.2.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.3.0->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.3.0->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.3.0->-r requirements.txt (line 1)) (4.1.2)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim==3.3.0->-r requirements.txt (line 1)) (1.19.5)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=f9e8decc449d7227f131741168b6d49fe0af05cd359766ab76e8828ec7ae5762\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: gensim, wget\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-3.3.0 wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yPpljkplmkq"
      },
      "source": [
        "!python prep_data.py --glove"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjlzOevhAXxV",
        "outputId": "9a05c6ae-f579-413e-97b5-e9a5241cf582"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWXlV8H69l9p",
        "outputId": "4fc9a579-412e-40cf-d77d-6d869b88751b"
      },
      "source": [
        "!python train.py --glove"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building dictionary...\n",
            "tcmalloc: large alloc 1233903616 bytes == 0x7c396000 @  0x7fb6684c8615 0x578a15 0x50a1cc 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x50ad03 0x634e72 0x634f27 0x6386df 0x639281 0x4b0dc0 0x7fb6680c4bf7 0x5b259a\n",
            "tcmalloc: large alloc 1542381568 bytes == 0x12516000 @  0x7fb6684c8615 0x578a15 0x50a1cc 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x50ad03 0x634e72 0x634f27 0x6386df 0x639281 0x4b0dc0 0x7fb6680c4bf7 0x5b259a\n",
            "Loading training dataset...\n",
            "WARNING:tensorflow:From train.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2021-02-07 01:36:48.243159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-02-07 01:36:48.342307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-07 01:36:48.343186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-02-07 01:36:48.372853: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-02-07 01:36:48.556371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-02-07 01:36:48.657436: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-02-07 01:36:48.681461: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-02-07 01:36:48.917611: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-02-07 01:36:49.044732: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-02-07 01:36:49.551958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-02-07 01:36:49.552248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-07 01:36:49.552874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-07 01:36:49.559331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-02-07 01:36:49.574076: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-02-07 01:36:49.729288: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-02-07 01:36:49.732616: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x20112c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-02-07 01:36:49.732659: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-02-07 01:36:49.884348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-07 01:36:49.885060: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2011100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-02-07 01:36:49.885089: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2021-02-07 01:36:49.887965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-07 01:36:49.888483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-02-07 01:36:49.888574: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-02-07 01:36:49.888611: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-02-07 01:36:49.888635: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-02-07 01:36:49.888660: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-02-07 01:36:49.888682: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-02-07 01:36:49.888702: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-02-07 01:36:49.888722: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-02-07 01:36:49.888806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-07 01:36:49.889388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-07 01:36:49.889868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-02-07 01:36:49.892511: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-02-07 01:36:49.894176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-02-07 01:36:49.894205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2021-02-07 01:36:49.894217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2021-02-07 01:36:49.898205: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-07 01:36:49.898823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-07 01:36:49.899434: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-02-07 01:36:49.899583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /content/drive/My Drive/ColabNotebooks/NLP/text-summarization-tensorflow/model.py:19: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/ColabNotebooks/NLP/text-summarization-tensorflow/model.py:20: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/ColabNotebooks/NLP/text-summarization-tensorflow/model.py:22: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "Loading Glove vectors...\n",
            "tcmalloc: large alloc 2301001728 bytes == 0x1670e000 @  0x7fb6684c9001 0x7fb66595e4ff 0x7fb6659aeb08 0x7fb6659b2ac7 0x7fb665a511a3 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x508f37 0x594a01 0x549e8f 0x5515c1 0x5a9dac 0x50a433 0x50beb4 0x507be4 0x50ad03 0x634e72 0x634f27 0x6386df\n",
            "WARNING:tensorflow:From /content/drive/My Drive/ColabNotebooks/NLP/text-summarization-tensorflow/model.py:35: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/ColabNotebooks/NLP/text-summarization-tensorflow/model.py:40: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/rnn/python/ops/rnn.py:239: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/My Drive/ColabNotebooks/NLP/text-summarization-tensorflow/model.py:101: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/ColabNotebooks/NLP/text-summarization-tensorflow/model.py:103: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/ColabNotebooks/NLP/text-summarization-tensorflow/model.py:106: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:54: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "2021-02-07 01:48:51.741467: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 147160800 exceeds 10% of system memory.\n",
            "2021-02-07 01:48:51.803831: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 147160800 exceeds 10% of system memory.\n",
            "2021-02-07 01:48:51.859096: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 147160800 exceeds 10% of system memory.\n",
            "2021-02-07 01:48:51.887730: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 147160800 exceeds 10% of system memory.\n",
            "2021-02-07 01:48:51.915647: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 147160800 exceeds 10% of system memory.\n",
            "WARNING:tensorflow:From train.py:55: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:55: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "\n",
            "Iteration starts.\n",
            "Number of batches per epoch : 59437\n",
            "/content/drive/My Drive/ColabNotebooks/NLP/text-summarization-tensorflow/utils.py:89: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  outputs = np.array(outputs)\n",
            "2021-02-07 01:49:21.416146: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "step 1000: loss = 48.43010330200195\n",
            "step 2000: loss = 36.57551574707031\n",
            "step 3000: loss = 35.330596923828125\n",
            "step 4000: loss = 34.04059982299805\n",
            "step 5000: loss = 36.0131950378418\n",
            "step 6000: loss = 34.294952392578125\n",
            "step 7000: loss = 32.458560943603516\n",
            "step 8000: loss = 30.844322204589844\n",
            "step 9000: loss = 28.246288299560547\n",
            "step 10000: loss = 28.019411087036133\n",
            "step 11000: loss = 28.40631866455078\n",
            "step 12000: loss = 23.838911056518555\n",
            "step 13000: loss = 29.049949645996094\n",
            "step 14000: loss = 23.599327087402344\n",
            "step 15000: loss = 40.78746032714844\n",
            "step 16000: loss = 36.56446838378906\n",
            "step 17000: loss = 35.97557830810547\n",
            "step 18000: loss = 27.691402435302734\n",
            "step 19000: loss = 32.590431213378906\n",
            "step 20000: loss = 29.642826080322266\n",
            "step 21000: loss = 33.85121536254883\n",
            "step 22000: loss = 23.191795349121094\n",
            "step 23000: loss = 27.98525619506836\n",
            "step 24000: loss = 36.08201599121094\n",
            "step 25000: loss = 44.74150848388672\n",
            "step 26000: loss = 35.44746398925781\n",
            "step 27000: loss = 43.63800048828125\n",
            "step 28000: loss = 37.004085540771484\n",
            "step 29000: loss = 36.30020523071289\n",
            "step 30000: loss = 37.42384338378906\n",
            "step 31000: loss = 28.872995376586914\n",
            "step 32000: loss = 34.777645111083984\n",
            "step 33000: loss = 31.537921905517578\n",
            "step 34000: loss = 36.467018127441406\n",
            "step 35000: loss = 34.780067443847656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb86dC8jy7Bu",
        "outputId": "feac4630-60e9-40f0-cea5-cf63c3f9b584"
      },
      "source": [
        "!python test.py"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"test.py\", line 7, in <module>\n",
            "    with open(\"args.pickle\", \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'args.pickle'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_ybVxepr3_V",
        "outputId": "e1d6acdb-8fcf-4285-bbfc-c2bae6ae04d3"
      },
      "source": [
        "%ls -l"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 284868\n",
            "drwx------ 2 root root      4096 Feb  7 00:28 \u001b[0m\u001b[01;34mglove\u001b[0m/\n",
            "-rw------- 1 root root      1068 Feb  6 18:18 LICENSE\n",
            "-rw------- 1 root root      6939 Feb  6 18:18 model.py\n",
            "-rw------- 1 root root      7187 Feb  7 00:06 model-upgraded.py\n",
            "-rw------- 1 root root       999 Feb  6 18:18 prep_data.py\n",
            "drwx------ 2 root root      4096 Feb  7 00:31 \u001b[01;34m__pycache__\u001b[0m/\n",
            "-rw------- 1 root root      5109 Feb  6 18:18 README.md\n",
            "-rw------- 1 root root     21965 Feb  7 00:06 report.txt\n",
            "-rw------- 1 root root        36 Feb  6 18:18 requirements.txt\n",
            "-rw------- 1 root root    765674 Feb  6 18:18 sample_data.zip\n",
            "drwx------ 6 root root      4096 Apr 12  2016 \u001b[01;34msumdata\u001b[0m/\n",
            "-rw------- 1 root root 290866023 Feb  6 18:35 summary.tar.gz\n",
            "-rw------- 1 root root      1771 Feb  6 18:18 test.py\n",
            "-rw------- 1 root root      4388 Feb  6 18:18 train.py\n",
            "-rw------- 1 root root      4428 Feb  7 00:00 train-upgraded.py\n",
            "-rw------- 1 root root      4023 Feb  6 18:18 utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}